### Decision Tree Theory

A decision tree is a supervised learning algorithm that is mainly used for classification and regression tasks. It splits the data into subsets based on the most significant attribute or feature at each node, creating a tree-like model of decisions. Each internal node represents a decision based on a feature, each branch represents the outcome of that decision, and each leaf node represents a class label or continuous value.

Decision trees are popular because they are simple to understand and interpret, can handle both numerical and categorical data, and require little data preprocessing. They can also model complex decision boundaries and capture interactions between features.

However, decision trees have some limitations, such as their tendency to overfit the training data, especially when they are deep. They can be sensitive to small changes in the data, which can result in a completely different tree being generated.

### Code with Documentation

```python
# Importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn import tree
import matplotlib.pyplot as plt

# Reading the dataset from a URL
mca = pd.read_csv("https://raw.githubusercontent.com/apratim777/apratim777/master/salaries.csv")

# Displaying the first few rows of the dataset
print(mca.head())

# Displaying the last few rows of the dataset
print(mca.tail())

# Separating the input features and the target variable
inputs = mca.drop('salary_more_then_100k', axis='columns')
target = mca['salary_more_then_100k']

# Initializing LabelEncoder objects for encoding categorical variables
le_company = LabelEncoder()
le_job = LabelEncoder()
le_degree = LabelEncoder()

# Encoding categorical variables into numerical values
inputs['company_n'] = le_company.fit_transform(inputs['company'])
inputs['job_n'] = le_job.fit_transform(inputs['job'])
inputs['degree_n'] = le_degree.fit_transform(inputs['degree'])

# Dropping the original categorical columns after encoding
input_n = inputs.drop(['company', 'job', 'degree'], axis=1)

# Displaying the processed input features
print(input_n)

# Initializing the Decision Tree Classifier
model = tree.DecisionTreeClassifier()

# Training the model
model.fit(input_n, target)

# Evaluating the model's accuracy
accuracy = model.score(input_n, target)
print(f"Model Accuracy: {accuracy}")

# Predicting the target variable for a new sample
prediction = model.predict([[2, 1, 0]])
print(f"Prediction for [2, 1, 0]: {prediction}")
```

### Raw Data for Reference

```
company,job,degree,salary_more_then_100k
google,sales executive,bachelors,0
google,sales executive,masters,0
google,business manager,bachelors,1
google,business manager,masters,1
google,computer programmer,bachelors,0
google,computer programmer,masters,1
abc pharma,sales executive,masters,0
abc pharma,computer programmer,bachelors,0
abc pharma,business manager,bachelors,0
abc pharma,business manager,masters,1
facebook,sales executive,bachelors,1
facebook,sales executive,masters,1
facebook,business manager,bachelors,1
facebook,business manager,masters,1
facebook,computer programmer,bachelors,1
facebook,computer programmer,masters,1
```

### Summary

In this code, we read the dataset containing information about salaries based on company, job title, and degree. We then encoded the categorical variables into numerical values using `LabelEncoder` and trained a Decision Tree Classifier. The model was evaluated on the training data, and we also made a prediction for a new sample. Decision trees help us understand the decision-making process by visualizing the decision paths in the form of a tree structure.